# TimelapseFromPrompt
TimelapseFromPrompt is a tool for automatically generating object-centric timelapse videos using natural language prompts.

## ğŸ”¥ About

ğŸ” What it does

- Input: A regular video recording of any scene (e.g., quadruped, animals, drone).

- Step 1 â€“ Frame Extraction: Uses ffmpeg to extract frames from the video.

- Step 2 â€“ Object Detection: Applies GroundingDINO to detect the object of interest based on a user-defined text prompt.

- Step 3 â€“ Timelapse Creation: Selects and compiles relevant frames into a focused timelapse video of the specified object.

âš™ï¸ Features

- ğŸ’¬ Prompt-based detection â€“ Just describe what you want to track (e.g., "drone", "person walking", "red ball").

- ğŸï¸ Frame interval control â€“ Choose how often frames are sampled using frame_interval (default: 13).

- ğŸ“¦ Detection thresholds â€“ Tune BOX_THRESHOLD and TEXT_THRESHOLD for controlling detection sensitivity:

```python
BOX_THRESHOLD = 0.35
TEXT_THRESHOLD = 0.25
```
ğŸ” Dynamic frame interval â€“ Change frame interval mid-video to better highlight interesting segments.

## ğŸ› ï¸ Installation 

TODO


## â­ Troubleshooting

TODO

# âœ’ï¸ Citation

**TimelapseFromPrompt**

```BibText
@software{Guerrier_TimelapseFromPrompt_A_Prompt-Based_2025,
author = {Guerrier, Maeva and Soma, Karthik},
license = {MIT},
month = jul,
title = {{TimelapseFromPrompt: A Prompt-Based Tool for Object-Focused Timelapse Generation}},
url = {https://github.com/MaevaGuerrier/TimelapseFromPrompt},
version = {1.0.0},
year = {2025}
}
```

**Grounding dino**

```BibTeX
@article{liu2023grounding,
  title={Grounding dino: Marrying dino with grounded pre-training for open-set object detection},
  author={Liu, Shilong and Zeng, Zhaoyang and Ren, Tianhe and Li, Feng and Zhang, Hao and Yang, Jie and Li, Chunyuan and Yang, Jianwei and Su, Hang and Zhu, Jun and others},
  journal={arXiv preprint arXiv:2303.05499},
  year={2023}
}
```

